{"0": [{"name": "Rebuttal Synthesis Engine", "functionalities": ["Automatically parses the email content to extract comments from each reviewer.", "Categorizes comments into 'Strengths', 'Weaknesses', 'Questions', and 'Suggestions'.", "Generates a structured summary table in the new Google Doc with columns for 'Reviewer', 'Comment Category', 'Comment', and a blank column for 'Response'."], "reasoning": "This automates the tedious and error-prone task of manually copying and organizing reviewer feedback from the email into a document. It allows the user to immediately focus on the high-level task of formulating responses rather than the low-level task of data entry."}, {"name": "Argumentation Strategist", "functionalities": ["Analyzes a specific reviewer criticism, such as the request to compare 'Knoll' to a 'RAG- or CAG-based approach'.", "Generates several high-level counter-argument strategies based on the user's paper content.", "Suggests key differentiating concepts and supporting points for each strategy to strengthen the rebuttal."], "reasoning": "This tool will help the user overcome writer's block when facing challenging critiques. It provides structured, strategic starting points for their arguments, ensuring the responses are robust and well-considered."}, {"name": "Collaborative Rebuttal Hub", "functionalities": ["Creates a sidebar in Google Docs linked to the synthesized comments.", "Allows assignment of specific comments to co-authors (Diyi, Michael).", "Tracks the status of each response (e.g., 'To Draft', 'In Review', 'Completed').", "Centralizes threaded discussions for each point, separate from general document comments."], "reasoning": "This streamlines the collaboration process by creating a dedicated project management space within the document. It ensures clear ownership, progress tracking, and organized discussions, which is more efficient than untracked email chains or cluttered Google Doc comments."}, {"name": "Conference Compliance Guard", "functionalities": ["Scrapes the provided UIST author guide URL for rebuttal-specific constraints (e.g., length, word count, anonymity rules).", "Provides a real-time dashboard in the document tracking compliance with these rules.", "Issues warnings if the draft exceeds limits or violates a formatting guideline."], "reasoning": "This tool proactively prevents last-minute submission problems by ensuring the rebuttal adheres to specific conference guidelines throughout the writing process. It saves the user from stressful revisions right before the deadline."}, {"name": "Semantic Comment Grouper", "functionalities": ["Analyzes all extracted reviewer comments for semantic similarity.", "Automatically groups related points from different reviewers (e.g., all comments about the user study or evaluation).", "Suggests a thematic structure for the rebuttal based on these identified clusters."], "reasoning": "This tool helps create a more coherent and non-repetitive rebuttal. By grouping similar concerns, it allows the user to write a single, strong response that addresses multiple reviewers simultaneously, improving the rebuttal's structure and impact."}, {"name": "In-Doc Citation Assistant", "functionalities": ["Allows the user to highlight a claim within their Google Doc draft.", "Searches academic databases (e.g., Google Scholar, ACM Digital Library) for supporting or contrasting papers.", "Suggests relevant citations and allows one-click insertion in the correct ACM reference format."], "reasoning": "To address the need for a stronger comparison to RAG, this tool accelerates the research process by integrating literature search directly into the writing environment. It helps the user find and insert supporting evidence efficiently."}, {"name": "Diplomatic Tone Tuner", "functionalities": ["Scans the rebuttal draft for potentially defensive, aggressive, or dismissive language.", "Suggests alternative phrasing that is more constructive, respectful, and persuasive.", "Provides an overall 'Tone Score' for the document to gauge its professionalism."], "reasoning": "The tone of a rebuttal is critical for persuading reviewers. This tool acts as a specialized proofreader to help the user craft a response that is received positively, a common challenge in high-stakes academic writing."}, {"name": "Rebuttal Point Checklist", "functionalities": ["Generates an interactive checklist from all extracted reviewer criticisms in the Google Docs sidebar.", "Allows the user to mark points as 'addressed' as they write the corresponding response.", "Automatically links the checklist item to the relevant text in the document for easy navigation."], "reasoning": "This tool ensures that no reviewer comment is accidentally missed. It provides a clear, visual way to track progress and guarantee that every single point raised in the reviews has been addressed in the final draft."}, {"name": "Argument Visualization Mapper", "functionalities": ["Creates a mind map or flowchart from the rebuttal's structure.", "Visually links each reviewer's point to the user's core response and supporting claims.", "Allows for manual rearrangement to test and refine the logical flow of the argument."], "reasoning": "This tool helps the user structure and verify the logical integrity of their arguments. By visualizing the flow from criticism to response to evidence, they can identify weak links or convoluted reasoning before submission."}, {"name": "Co-author Update Summarizer", "functionalities": ["On demand, generates a concise summary of the current rebuttal draft.", "Highlights the key arguments made and which reviewer points have been addressed.", "Includes a list of unresolved points or questions specifically for the co-authors."], "reasoning": "This tool facilitates asynchronous collaboration by providing co-authors with a quick, digestible overview of the draft's status. It enables them to provide more focused and efficient feedback without needing to read the entire document from scratch each time."}], "1": [{"name": "Secure Login Troubleshooter", "functionalities": ["Detects common login errors like caps lock or incorrect username formats on institutional login pages.", "Provides single-click access to the university's official 'Forgot SUNet ID' or 'Reset Password' pages.", "Monitors for failed Duo Push notifications and automatically suggests alternative 2FA methods like sending a passcode via SMS."], "reasoning": "The user is actively and repeatedly failing to log into Stanford's system. This tool directly addresses the immediate barrier by providing context-aware help to resolve the credential and 2FA issues, enabling them to proceed with their task."}, {"name": "Federated Academic Search", "functionalities": ["Provides a single search interface that queries multiple Stanford-internal resources simultaneously after login (e.g., Stanford Libraries, CS Departmental Archives, faculty pages).", "Understands queries for non-public documents like 'internal beta paper' or 'in-progress draft'.", "Filters and ranks search results based on relevance to concepts found in the user's active rebuttal document in Google Docs."], "reasoning": "Once logged in, the user's next action will be to find a specific, potentially unlisted paper. This tool automates the inefficient and confusing process of searching across multiple, disparate university databases to find the resource quickly."}, {"name": "Institutional Access Session Manager", "functionalities": ["Maintains the authenticated session with the university portal in the background to prevent timeouts during research.", "Provides a one-click re-authentication button if a session does expire, using stored credentials to streamline the process.", "Caches recently accessed authenticated resources for temporary offline viewing or to prevent repeated downloads."], "reasoning": "Given the user's difficulty logging in, getting timed out would be highly frustrating. This tool prevents service interruptions from session expirations, ensuring the user can focus on their research without having to repeat the difficult login process."}, {"name": "Rebuttal-Focused Paper Analyzer", "functionalities": ["Scans a newly opened academic paper (PDF or web page) after the user finds it.", "Uses the reviewer comments from the user's Google Doc to automatically highlight passages in the found paper that are most relevant to the rebuttal.", "Generates a bulleted summary of the paper's key arguments that directly address the user's specific rebuttal points."], "reasoning": "After finding the Stanford paper, the user will need to read it and extract relevant information for their rebuttal. This tool accelerates this analysis by pinpointing the exact information needed to address the reviewer's feedback."}, {"name": "Gray Literature Finder", "functionalities": ["Specializes in finding non-peer-reviewed academic works by searching preprint servers (like arXiv), institutional repositories, and faculty lab websites.", "Uses the user's search query ('michael scott bernstein internal beta') to specifically look for documents labeled as 'tech reports,' 'drafts,' or 'beta versions'.", "Traces the citation network of unpublished works to discover other relevant, non-traditional sources."], "reasoning": "The user is looking for an 'internal beta paper,' which is a form of 'gray literature' not typically found in standard academic databases. This tool is purpose-built to locate such hard-to-find documents, which is precisely what the user needs."}, {"name": "Stanford Resource Navigator", "functionalities": ["After a successful login, it analyzes the user's prior Google search history ('michael scott bernstein').", "Presents a dynamic dashboard with direct links to the most probable locations for the paper within the Stanford ecosystem (e.g., '1. CS Tech Reports, 2. HCI Group Publications, 3. Prof. Bernstein's Faculty Page').", "Provides a brief description of the content found at each suggested location."], "reasoning": "A university's internal web is often a maze; a successful login doesn't guarantee the user knows where to look next. This tool acts as an intelligent guide, pointing the user directly to the most likely repositories for their target document."}, {"name": "Academic Credential Vault", "functionalities": ["A secure password manager specifically designed for academic credentials like SUNet IDs, library access codes, and ORCiD logins.", "Autofills correct usernames and passwords on university login pages to prevent typos and failed attempts.", "Flags institutional passwords that are nearing their expiration date based on university policies."], "reasoning": "The user's login failures are likely due to mistyping or forgetting the correct credentials. This vault would prevent this root problem by securely and accurately managing their various academic logins, streamlining access."}, {"name": "Cross-Document Argument Linker", "functionalities": ["Allows the user to highlight text in the found Stanford paper and create a persistent, bi-directional link to a specific reviewer comment in their Google Doc.", "When hovering over the link in the Google Doc, it displays a preview of the source text from the paper.", "Automatically generates a pre-formatted citation and summary of the linked evidence within the rebuttal draft."], "reasoning": "The user's ultimate goal is to connect evidence from the found paper to their rebuttal arguments. This tool creates a direct, traceable link between the supporting evidence and the claim, improving workflow and argument integrity."}, {"name": "Author Profile Deep Scanner", "functionalities": ["Performs a deep scan of a specific faculty member's university-hosted web pages (e.g., Michael S. Bernstein's Stanford profile).", "Identifies and lists all linked documents (PDF, DOCX) that are not indexed on major search engines like Google Scholar.", "Categorizes found documents into 'Publications,' 'Drafts,' 'Course Materials,' and 'Software' to help the user find the target resource."], "reasoning": "The 'internal beta paper' the user seeks is likely hosted on the author's personal or lab website, not a public repository. This tool automates the manual and tedious process of digging through a professor's website to find unlisted documents."}, {"name": "Citation-to-Rebuttal Drafter", "functionalities": ["Analyzes a user-selected passage from the source paper found on the Stanford site.", "Generates several draft sentences that integrate the finding into a rebuttal, offering different phrasing options (e.g., a direct comparison, an acknowledgement).", "Automatically formats the in-text citation and bibliography entry according to the specified conference style (e.g., UIST)."], "reasoning": "Bridging the gap between finding evidence and writing the argument is a key step. This tool helps the user convert a piece of evidence from the Stanford paper directly into polished, context-aware text for their rebuttal, accelerating the writing process."}], "2": [{"name": "Live Figure Sync", "functionalities": ["Scans a manuscript (e.g., LaTeX project) and its associated Google Drive folder to create a dependency map between figure source files (e.g., Python scripts, .ai, .fig) and their compiled versions referenced in the document.", "Monitors the source files for changes and, upon saving, automatically re-generates the figure (e.g., re-running the script to output a new PNG).", "Flags the specific figure in the manuscript as 'stale' and offers a one-click update to the latest version, ensuring consistency between source and document."], "reasoning": "The user's immediate TODO is to edit figures. This tool automates the tedious and error-prone process of updating figures in the manuscript after their source files have been changed, directly supporting this next action."}, {"name": "GDoc-to-LaTeX Task Bridge", "functionalities": ["Parses checklist items from the user's 'review synthesis' Google Doc.", "Creates an interactive overlay or sidebar within the user's LaTeX editor (e.g., Overleaf).", "Automatically links each checklist item to the relevant section or line of code in the LaTeX source (e.g., linking 'remove LM from Fig 2' to the '\\includegraphics' command for Figure 2).", "Allows the user to mark a task as complete in the LaTeX editor, which then automatically checks it off in the source Google Doc."], "reasoning": "The user needs to translate their high-level revision plan from a Google Doc into specific code changes. This tool bridges that gap, providing direct navigation and progress tracking between the plan and the manuscript itself."}, {"name": "Academic Project Archiver", "functionalities": ["Scans the user's Google Drive, identifying project folders by recognizing file structures common to academic papers (e.g., folders containing .tex, .bib, and figure files).", "Identifies and calculates the storage space used by intermediate and auxiliary files (e.g., .log, .aux, .bbl, multiple compiled PDFs).", "Provides a 'Clean Project' option to delete auxiliary files and an 'Archive Project' option to compress an entire folder of a past submission into a single .zip file to save space."], "reasoning": "This directly addresses the user's 'low on storage' notification by offering an intelligent, automated way to clean up project-specific clutter and free up space, preventing workflow interruptions."}, {"name": "Revision Justification Finder", "functionalities": ["Analyzes the specific revision instruction from the synthesis doc, such as 'remove the LM (Linear Models)'.", "Proactively searches academic databases (e.g., Google Scholar, ACM Digital Library) for papers that critique the user's removed method or propose the retained methods (from Figures 2 & 3) as alternatives in a similar context.", "Presents a summarized list of arguments from these papers that can be used to justify the revision in the manuscript."], "reasoning": "When making a significant revision like removing a model, the user will need to justify the change. This tool automates the search for supporting literature, saving the user time and strengthening their revised paper."}, {"name": "Institutional Login Sentinel", "functionalities": ["Detects repeated, rapid failed login attempts on a university SSO page.", "Checks the university's public IT status page for known outages to differentiate user error from system issues.", "If a Duo Push notification appears to time out, it automatically surfaces other available 2FA options on the page (e.g., 'Get SMS Passcode', 'Use Hardware Token') to prevent the user from having to restart the login process."], "reasoning": "The user is actively struggling with login and 2FA. This tool provides a more intelligent and proactive solution than a simple password manager by diagnosing the root cause of login failure and streamlining the recovery process."}, {"name": "Contribution Consistency Checker", "functionalities": ["Scans the manuscript to extract all explicit contribution claims, typically from the Introduction and Conclusion sections.", "Maps each claim to the corresponding evidence in the paper, such as figures, tables, or results described in the body.", "Flags any claims that appear to be unsupported or have become inconsistent with the paper's content following revisions."], "reasoning": "After performing revisions like removing a model, the paper's contributions may change. This tool helps ensure the final manuscript's claims are coherent and robustly supported by its content, preventing a common reviewer criticism."}, {"name": "Automated Caption Editor", "functionalities": ["Integrates with the 'Live Figure Sync' tool to detect when a figure has been changed.", "Analyzes the figure's existing caption in the manuscript.", "Suggests specific edits to the caption text to reflect the changes in the figure, such as removing mentions of elements that are no longer present (e.g., the Linear Models)."], "reasoning": "The user's task is not just to change the figure image, but also its description. This tool automates the often-forgotten but critical step of updating figure captions to match their new content."}, {"name": "Section Remodeler", "functionalities": ["Generates a visual, interactive mind-map or flowchart of the paper's section structure based on the LaTeX source.", "Allows the user to drag and drop sections to re-order them.", "Automatically refactors the underlying LaTeX code to reflect the new structure, correctly re-numbering all internal cross-references to sections, figures, and tables to prevent breaking the document."], "reasoning": "Major revisions often require significant restructuring of the paper's narrative. This tool simplifies the complex and error-prone task of reordering sections in LaTeX, allowing the user to focus on logic and flow."}, {"name": "Cross-Document Edit Tracker", "functionalities": ["Links the review synthesis Google Doc with the manuscript file.", "When the user implements a revision, the tool allows them to highlight the changed text in the manuscript and link it back to the specific reviewer comment or TODO item in the Google Doc.", "Creates a 'Changelog' summary view showing which comments have been addressed and providing direct links to the resulting edits in the paper."], "reasoning": "The user needs to ensure every reviewer point is addressed. This tool creates an explicit, auditable trail between the feedback and the corresponding changes in the manuscript, improving organization and accountability."}, {"name": "Collaborative Revision Heatmap", "functionalities": ["Creates a visual overlay on the manuscript PDF that highlights sections based on recent revision activity.", "Uses different colors to show edits made by different co-authors (e.g., Dorothy, Michael, Diyi).", "Provides a timeline scrubber to see how the document has evolved over the past day or week, pinpointing areas of intense work."], "reasoning": "Working with co-authors requires coordination. This tool provides a quick, at-a-glance understanding of where collaborators are focusing their efforts, improving team awareness and reducing redundant work."}], "3": [{"name": "Surgical Model Extractor", "functionalities": ["Scans a LaTeX manuscript and identifies all mentions, equations, results, and citations related to a user-specified concept (e.g., 'Linear Models', 'LM').", "Traces dependencies to find associated table rows, figure references, and labels connected to the concept.", "Generates a unified 'diff' view showing all proposed deletions and modifications across multiple files.", "Executes the removal across the entire project with a single user confirmation, ensuring no remnants are left."], "reasoning": "The user's immediate next action is to remove the Linear Models from the paper. This tool automates the tedious and error-prone process of finding and deleting every mention, reference, and result associated with the model, preventing inconsistencies."}, {"name": "Figure-Code-Caption Verifier", "functionalities": ["Links a figure in the manuscript (e.g., Figure 2) to its source code generator (e.g., a Python script).", "Parses the figure generation script to identify the data series being plotted (e.g., 'Model A', 'Model B').", "Compares the plotted data series with the concepts mentioned in the figure's LaTeX caption.", "Flags discrepancies, such as when a model ('LM') is mentioned in the caption but is no longer present in the plotting code."], "reasoning": "After removing the LM from the data, the user's next action is to update Figures 2 and 3 and their captions. This tool prevents a common error where the figure is updated but the caption still describes the old version, ensuring visual and textual consistency."}, {"name": "Narrative Integrity Analyst", "functionalities": ["Analyzes the paper's high-level structure (Introduction, Methods, Results, Discussion) after a major revision.", "Identifies logical and narrative breaks caused by the revision, such as promising a three-model comparison in the introduction but only presenting two in the results.", "Highlights these 'narrative gaps' in the manuscript.", "Suggests transitional sentences or section edits to restore a coherent flow."], "reasoning": "Removing a core component like the LM will disrupt the paper's narrative flow, a predicted challenge for the user. This tool helps the user identify and repair these logical gaps to ensure the revised paper is still coherent and persuasive."}, {"name": "Targeted Co-author Review Requester", "functionalities": ["Integrates with the project's version control (e.g., Git, Overleaf History).", "Allows the user to select a set of changes corresponding to a specific task (e.g., 'Remove LM').", "Generates a concise summary of the changes, including before-and-after views of text and figures.", "Sends a focused review request to co-authors (e.g., Michael, Diyi) with a direct link to this summary, creating a dedicated discussion thread for the specific revision."], "reasoning": "The user needs to collaborate with co-authors on these revisions. This tool streamlines the feedback process by packaging a major change into a single, easy-to-review request, saving co-authors from having to search the entire document for what's new."}, {"name": "Cross-Reference Integrity Auditor", "functionalities": ["Performs a static analysis of the LaTeX source code before compilation.", "Parses all `\\label`, `\\ref`, and `\\cite` commands to build a dependency map.", "Identifies 'orphaned' references (a `\\ref` pointing to a `\\label` that has been or is about to be deleted).", "Reports a clear list of potential breakages, allowing the user to fix them proactively."], "reasoning": "A key part of the user's next action\u2014removing the LM\u2014involves deleting associated labels for sections, figures, and tables. This tool preemptively catches broken cross-references, saving the user from debugging cryptic LaTeX compilation errors."}, {"name": "Semantic Diff Viewer", "functionalities": ["Compares two versions of a manuscript and understands its academic structure.", "Generates a human-readable summary of changes, such as 'Removed 2 paragraphs from Methods' or 'Updated Figure 3 caption'.", "Visually groups related line-by-line edits under these semantic summary headings.", "Allows filtering of changes by section or type (e.g., 'show only text changes in the Results section')."], "reasoning": "As the user revises the paper, they and their collaborators will need to track changes. This tool provides a much more intuitive view of revisions than a standard diff, making it easier to understand the evolution of the manuscript."}, {"name": "Revision Impact Forecaster", "functionalities": ["Allows the user to specify a planned change, such as 'delete Section 4.1' or 'rename concept X to Y'.", "Scans the entire project repository, including manuscript source, figure scripts, and supplementary documents.", "Generates a 'blast radius' report detailing all files, cross-references, figures, and code variables that would be affected by the change.", "Estimates the number of manual edits that will be required."], "reasoning": "Before embarking on the next revision, the user can use this tool to understand the full scope of the task. It helps in planning and prevents the 'oh no, this is a bigger job than I thought' problem by revealing all downstream consequences of an edit upfront."}, {"name": "Project-Aware Storage Optimizer", "functionalities": ["Scans Google Drive and identifies academic project folders by their structure.", "Identifies not just auxiliary files, but also large, redundant assets like uncompressed source images, old video clips, and intermediate datasets that are no longer referenced by the final analysis scripts.", "Generates a 'Replication Package' suggestion, which includes only the files needed to reproduce the paper's final results.", "Provides a one-click option to archive the non-essential, large files into a compressed folder, freeing up significant space."], "reasoning": "The user is currently receiving storage limit warnings on Google Drive. This tool offers a more intelligent solution than the existing 'Archiver' by specifically identifying large, redundant assets within a project, addressing the user's explicit pain point."}, {"name": "Rebuttal Justification Synthesizer", "functionalities": ["Takes as input the original reviewer comment and the user's implemented revision (e.g., 'removed Linear Models').", "Generates several draft sentences for the rebuttal document that strategically explain the change.", "Offers different rhetorical frames for the justification, such as 'To improve focus...', 'In response to reviewer feedback...', or 'To simplify the core contribution...'.", "Can integrate with citation tools to pull in evidence supporting the decision."], "reasoning": "After revising the paper, the user will need to justify their changes in the rebuttal. This tool accelerates that writing process by providing well-phrased, strategic explanations for the specific actions taken, like removing the LM."}, {"name": "Alternative Visualization Proposer", "functionalities": ["Analyzes the data source (e.g., CSV file, data frame in a script) used for an existing figure (like Figures 2 and 3).", "Understands the structure of the data (e.g., categorical, time-series, distribution).", "Suggests alternative, scientifically appropriate chart types (e.g., 'This bar chart could also be a box plot to show variance' or 'a slopegraph to emphasize change').", "Provides boilerplate code snippets in Python or R to generate the suggested visualizations."], "reasoning": "The user is currently focused on editing Figures 2 and 3. This tool augments their capabilities by suggesting potentially more effective ways to present their revised data, helping improve the paper's communicative power during the revision process."}], "4": [{"name": "Devil's Advocate Argument Probe", "functionalities": ["Analyzes a user-drafted rebuttal argument.", "Generates potential counter-rebuttals and follow-up questions a skeptical reviewer might ask.", "Highlights logical fallacies, unsupported claims, or language that might be perceived as hand-waving.", "Suggests areas where additional evidence or data would be needed to make the argument unassailable."], "reasoning": "The user needs to formulate robust defenses against criticisms like 'LIMITED NOVELTY'. This tool would help them stress-test their own arguments before submission, anticipating the reviewers' reactions and strengthening their position."}, {"name": "Comparative Terminology Explainer", "functionalities": ["Given a set of technical terms (e.g., 'Knoll', 'MCP', 'RAG', 'CAG'), it scrapes recent academic papers and technical blogs for definitions.", "Generates a comparative table highlighting the core mechanics, primary use cases, and key differences between the concepts.", "Provides example sentences that correctly differentiate the user's work ('Knoll') from the others."], "reasoning": "The user is struggling to clarify the significance of 'Knoll' in light of similar-sounding technologies. This tool provides the specific, nuanced information needed to write a clear and convincing differentiation in the rebuttal."}, {"name": "Rebuttal-to-Manuscript Promise Tracker", "functionalities": ["Scans the rebuttal document for phrases indicating a promised change (e.g., 'We will add...', 'We have revised...', 'We will clarify...').", "Links these promises to specific sections or figures in the main manuscript (e.g., a promise to clarify novelty links to the Introduction).", "Creates a pre-submission checklist to verify that every promise made in the rebuttal has been implemented in the final paper draft."], "reasoning": "The user is managing changes in a separate rebuttal doc and must apply them to a manuscript. This tool prevents a critical error where a promised revision is mentioned in the rebuttal but forgotten in the actual paper, ensuring consistency."}, {"name": "Precedent-Based Rebuttal Phrasing", "functionalities": ["Searches a database of public (or user-provided) rebuttals from the target conference (UIST).", "Given a specific reviewer criticism type (e.g., 'Limited Novelty', 'Unfair Evaluation'), it finds examples of successful rhetorical strategies and phrasing used by other authors.", "Suggests sentence stems and argument structures that have proven effective for similar issues at that specific venue."], "reasoning": "Addressing reviewer comments is a specific genre of writing. This tool helps the user adopt the correct tone and argumentative style by learning from successful past examples, increasing the persuasiveness of their response."}, {"name": "Revision Impact Forecaster", "functionalities": ["Simulates the impact of a major revision, like 'remove the Linear Models (LM)'.", "Identifies all sections of the paper where the narrative may become inconsistent as a result of the removal.", "Predicts potential new criticisms that could arise from the change (e.g., 'The evaluation now seems less comprehensive').", "Suggests preemptive sentences to add to the manuscript to address these predicted follow-up issues."], "reasoning": "The user is making a significant change by removing the LM. This tool helps them see beyond the immediate edit and anticipate the second-order effects on their paper's narrative and how a reviewer might react to the modified version."}, {"name": "Post-Revision Figure Narrator", "functionalities": ["Analyzes the visual content of a revised figure (e.g., Figure 2 after the LM is removed).", "Generates a bulleted list of the key observations and takeaways from the *new* version of the figure.", "Compares the new takeaways to the existing figure caption and highlights discrepancies.", "Suggests a revised caption that accurately reflects the updated figure's main point."], "reasoning": "The user must retain Figures 2 and 3 after removing the LM, which means their meaning will change. This tool helps rewrite the surrounding text and captions by providing a fresh, objective summary of what the new figure actually shows."}, {"name": "Contribution Claim Amplifier", "functionalities": ["Extracts all contribution claims from the manuscript's introduction and conclusion.", "Analyzes the claims for strength, specificity, and clarity against templates of high-impact claims from top papers.", "Suggests alternative phrasing to make the claims more powerful and precise, for example, by adding comparative clauses ('...which reduces error by X% over prior art')."], "reasoning": "The user needs to address 'UNCLEAR SIGNIFICANCE' and 'LIMITED NOVELTY'. This tool directly targets the language used to frame the paper's contribution, helping the user refine it for maximum impact and clarity."}, {"name": "Reviewer Persona Filter", "functionalities": ["Analyzes the complete text from each reviewer (R1, R3, 2AC) to infer their primary concerns (e.g., 'R1 focuses on methodology', 'R3 on novelty').", "Allows the user to view their draft rebuttal through a 'filter' for each reviewer persona.", "Highlights arguments in the rebuttal that a specific reviewer is likely to scrutinize most heavily, or points they may find unconvincing."], "reasoning": "A successful rebuttal must satisfy multiple, distinct reviewers. This tool helps the user tailor their arguments, ensuring the response directly addresses the core anxieties of each individual reviewer, rather than being a generic defense."}, {"name": "Concession Strategy Advisor", "functionalities": ["Identifies reviewer comments that are factually correct or difficult to argue against.", "Suggests strategic ways to concede a point gracefully without undermining the paper's core contribution.", "Provides templates for phrasing, such as acknowledging a limitation and positioning it as valuable future work.", "Differentiates between points that must be defended and those that are safer to concede."], "reasoning": "Not every reviewer point can or should be fought; fighting every point can appear defensive. This tool helps the user build goodwill and credibility by strategically agreeing with certain points, strengthening the overall rebuttal."}, {"name": "Fairness Argument Checklist", "functionalities": ["Focuses specifically on the 'Fairness of the Evaluation' criticism from reviewer R3.", "Generates an interactive checklist based on established fairness criteria in HCI/CSCW research (e.g., representation, bias in stimuli, task design).", "Prompts the user to articulate how their study design addresses each item on the checklist.", "Helps structure the part of the rebuttal dedicated to defending the evaluation's fairness."], "reasoning": "A generic 'fairness' criticism requires a structured, evidence-based response. This tool provides a scaffold based on academic best practices, ensuring the user's defense of their evaluation is thorough, systematic, and convincing."}], "5": [{"name": "Novelty Framework Identifier", "functionalities": ["Analyzes the paper abstract and reviewer comments to understand the context of the work (e.g., 'Knoll' as an HCI tool).", "Scans a built-in knowledge base of successful UIST/CHI papers to identify established patterns for arguing novelty (e.g., Technological, Methodological, Empirical, Social).", "Suggests the most appropriate novelty framework for 'Knoll', such as framing its 'plugability' and use of existing platforms as a 'Methodological' or 'Artifactual' contribution.", "Provides sentence stems and paragraph structures to help the user articulate this specific type of novelty in the rebuttal."], "reasoning": "The user needs to address the specific and difficult criticism of 'UIST-ful novelty in interactions'. This tool moves beyond generic advice to provide a strategic framework for arguing novelty that is grounded in the norms and successful patterns of the target academic venue."}, {"name": "Technical Trade-off Justifier", "functionalities": ["Takes as input a specific technical choice under review, such as the 'voyage-3-lite model'.", "Searches academic and technical sources for performance benchmarks, computational costs, and typical use cases for that model and its common alternatives (e.g., RAG, CAG).", "Generates a comparative table outlining the trade-offs (e.g., speed vs. accuracy, deployment simplicity vs. feature complexity).", "Drafts sentences for the rebuttal that justify the user's choice in the context of their system's goals, for instance, arguing that 'voyage-3-lite' was chosen for its efficiency and suitability for a lightweight browser extension."], "reasoning": "This tool directly helps the user defend a specific technical implementation ('voyage-3-lite model'), a key weakness identified by reviewers. It provides the evidence needed to turn a technical query into a well-reasoned defense of their engineering decisions."}, {"name": "Weakness-to-Strength Reframer", "functionalities": ["Allows the user to input a specific weakness cited by a reviewer (e.g., 'evaluation metrics are limited').", "Prompts the user to link this weakness to an intentional design strength (e.g., 'successful public deployment').", "Generates several rhetorical phrasing options that strategically connect the two, framing the perceived weakness as a deliberate trade-off for a greater strength.", "Example output: 'While we acknowledge the focus on a specific set of metrics, this was a deliberate choice to align our evaluation with the real-world usage patterns observed in our successful public deployment.'"], "reasoning": "The user needs to defend their work by highlighting its strengths, such as 'plugability' and 'public deployment'. This tool provides a concrete mechanism for rhetorically reframing reviewer criticisms as positive, intentional design choices, strengthening the overall argument."}, {"name": "Rebuttal Word Budget Allocator", "functionalities": ["Scans the list of reviewer criticisms in the Google Doc.", "Prompts the user to assign a priority level (High, Medium, Low) to each point, automatically suggesting a higher priority for comments from the Associate Chair (AC).", "Given the conference word limit for the rebuttal, it calculates and assigns a suggested word count for the response to each point.", "Provides a live-updating sidebar in Google Docs that tracks the word count used for each response against its allocated budget."], "reasoning": "Rebuttals have strict length limits, forcing authors to be concise. This tool helps the user strategically manage their limited space, ensuring they dedicate the most effort to addressing the most critical comments without exceeding the overall limit."}, {"name": "Evaluation Methodology Benchmarker", "functionalities": ["User inputs their research area ('HCI') and evaluation context ('in-the-wild study of a browser extension').", "Scrapes a database of papers from top-tier conferences (UIST, CHI, CSCW) with similar evaluations.", "Generates a report summarizing common evaluation metrics, participant demographics, and study designs used in comparable research.", "Provides citations that can be used in the rebuttal to defend the user's chosen metrics as being consistent with established practices or to thoughtfully position them as novel."], "reasoning": "To address the reviewer criticism about 'evaluation metrics', the user needs to ground their defense in the established norms of their field. This tool provides the specific evidence and citations needed to justify their methodology or concede a point gracefully."}, {"name": "Promise-to-Implementation Verifier", "functionalities": ["Parses the final rebuttal document to extract all explicit promises of future changes (e.g., 'We will add a discussion of...', 'We have clarified Figure 2...').", "Links to the manuscript's source files (e.g., LaTeX project).", "Performs a semantic search on the revised manuscript to verify if a corresponding edit has been made for each promise.", "Generates a pre-submission report flagging any promises from the rebuttal that do not appear to have been implemented in the paper, preventing inconsistencies."], "reasoning": "A common failure point is not fully implementing the changes promised in a rebuttal. This tool automates the verification process, ensuring the final paper aligns with the commitments made to the reviewers, which is a crucial step after the rebuttal is accepted."}, {"name": "Contribution Claim Decomposer", "functionalities": ["Analyzes the main contribution claims in the user's paper.", "Decomposes each high-level claim (e.g., 'Knoll is a novel plugable system') into its constituent parts (e.g., 'novelty', 'plugability', 'system').", "Scans the rebuttal draft to check if each part of the claim is adequately defended against reviewer critiques.", "Highlights claims that are either not fully supported by the rebuttal arguments or are directly undermined by concessions made to reviewers."], "reasoning": "The user is struggling with 'clarity of contribution framing'. This tool helps ensure that the core claims of the paper are consistently and robustly defended throughout the rebuttal, preventing a mismatch between what the paper claims and what the rebuttal argues."}, {"name": "Public Deployment Evidence Helper", "functionalities": ["Given a link to the publicly deployed tool (e.g., a Chrome Web Store page for 'Knoll').", "Scrapes the page for key evidence points: number of active users, average star rating, and snippets from positive user reviews.", "Summarizes this quantitative and qualitative data into concise, rebuttal-ready sentences.", "Example output: 'To demonstrate its real-world utility, Knoll has been successfully deployed to over 1,000 active users, achieving an average rating of 4.8 stars.'"], "reasoning": "The user wants to leverage the 'successful public deployment' of Knoll as a key strength. This tool automates the process of gathering and formatting this powerful, real-world evidence, making it easy to integrate into the rebuttal."}, {"name": "Rhetorical Strategy Analyst", "functionalities": ["Categorizes each reviewer comment by type (e.g., Misunderstanding, Methodological Critique, Request for Clarification).", "For each category, it suggests the most effective rhetorical strategy (e.g., for 'Misunderstanding', suggest a 'Respectful Correction' strategy; for 'Methodological Critique', suggest a 'Justify or Concede' strategy).", "Provides phrasing templates for each strategy, such as 'We thank the reviewer for this question, which highlights a point we must clarify...' for a correction.", "Analyzes the user's draft to see which strategies are being used and if they align with the comment type."], "reasoning": "Writing a rebuttal is as much about rhetorical strategy as it is about facts. This tool acts as a coach, helping the user choose the most effective way to respond to different kinds of criticism, which is more nuanced than simply checking for a diplomatic tone."}, {"name": "Acronym and Jargon Consistency Linter", "functionalities": ["Scans the Google Doc rebuttal for all multi-word capitalized phrases and potential acronyms (e.g., 'Human-Computer Interaction', 'HCI').", "Builds a dictionary of all jargon and acronyms used.", "Flags inconsistencies, such as using an acronym before it has been defined, or defining an acronym and never using it again.", "Checks for consistent usage (e.g., flagging if both 'RAG' and 'R.A.G.' are used)."], "reasoning": "A polished, professional rebuttal must be clear and consistent in its use of technical language. This specialized linter automates the tedious but crucial task of ensuring all acronyms and jargon are defined and used correctly, improving the rebuttal's clarity and professionalism."}], "6": [{"name": "Statistical Transformation Assistant", "functionalities": ["Connects to a data file (e.g., CSV) and allows the user to select variables ('OC', 'users', 'total_posts').", "Automatically generates visualizations like histograms and Q-Q plots to help the user verify the distribution of each variable.", "Runs normality tests (e.g., Shapiro-Wilk) and suggests statistically appropriate transformations (e.g., logarithmic, square root) for skewed data.", "Generates a boilerplate justification sentence for the methodology section of the paper explaining why the transformation was necessary."], "reasoning": "This tool directly supports the user's next action of adding logarithmic transformations to their ZINB models by first helping them 'verify their distribution' and then justifying the choice, automating a tedious statistical workflow."}, {"name": "Rebuttal-Linked Code Refactorer", "functionalities": ["Links the 'TODO' list in the 'Memes CSCW review synthesis' Google Doc to a directory of analysis and figure-generation scripts (e.g., Python, R).", "When the user selects the task 'remove the Linear Models (LM)', the tool scans the codebase and identifies all variables, data series, and plotting commands associated with 'LM'.", "Provides a 'one-click' option to comment out or delete all identified code blocks, ensuring the model is removed comprehensively from the analysis.", "Flags figures (e.g., Figure 2, Figure 3) whose generation scripts were modified, creating a reminder to re-compile and re-insert them into the manuscript."], "reasoning": "The user must 'remove the Linear Models (LM) but retain Figure 2 and Figure 3'. This tool automates the error-prone process of editing the underlying code, ensuring the change is made consistently and completely."}, {"name": "Argument Re-Framing Engine", "functionalities": ["User inputs a revision made in response to reviewer feedback, such as 'Removed the Linear Model'.", "The tool generates several phrasing options for the rebuttal that frame the revision positively using different rhetorical strategies.", "Example frames include: 'The Refinement Frame' (e.g., 'To enhance clarity...'), 'The Focus Frame' (e.g., 'To better highlight the performance of our core models...'), and 'The Simplification Frame' (e.g., 'For a more parsimonious model...')."], "reasoning": "After removing the LM, the user will need to justify this change in the rebuttal. This tool helps them move beyond a simple statement of fact to strategically frame the revision as an improvement to the paper."}, {"name": "Model Update Results Reporter", "functionalities": ["Compares two versions of a statistical model's output (e.g., before and after applying log transformations).", "Automatically identifies significant changes in coefficients, p-values, or model fit statistics (e.g., AIC, BIC).", "Generates draft sentences to be inserted into the results section of the manuscript, describing the impact of the update.", "Example output: 'After applying a log transformation to the 'users' variable, its coefficient became significant (\u03b2 = 1.52, p < .01), strengthening our original hypothesis.'"], "reasoning": "After the user adds log transformations and re-runs their ZINB models, they will need to update the text of their paper. This tool automates the tedious and error-prone process of reporting these numerical changes."}, {"name": "Strength Articulation Helper", "functionalities": ["User inputs a key strength of their system, such as 'plugability' or 'platform agnosticism'.", "The tool scrapes a database of high-impact papers from the target venue (CSCW) to find examples of how similar strengths were successfully argued.", "Provides the user with powerful sentence stems, impactful vocabulary, and paragraph structures to compellingly describe their system's advantages.", "Generates a statement like: 'A core contribution of Knoll is its novel 'plugability,' which, unlike monolithic systems, allows seamless integration into existing user workflows (e.g., Google Docs), thereby lowering the barrier to adoption.'"], "reasoning": "The user needs to highlight specific strengths of the 'Knoll' system. This tool helps them articulate these strengths not just as features, but as compelling research contributions, using language that resonates with the target academic community."}, {"name": "Side-by-Side Figure-Caption Verifier", "functionalities": ["Displays a revised figure (e.g., Figure 2 without the LM) next to its corresponding caption text from the manuscript.", "Uses OCR to read the legend and labels directly from the figure image.", "Highlights any terms mentioned in the caption text (e.g., 'Linear Model') that are no longer present in the figure's legend.", "Allows for real-time editing of the caption to ensure it perfectly matches the final version of the visualization."], "reasoning": "The user must revise Figures 2 and 3 after removing the LM. This tool prevents a common error where the figure is updated but the caption still refers to the old version, ensuring visual and textual consistency."}, {"name": "Evaluation Precedent Finder", "functionalities": ["User inputs key characteristics of their evaluation: 'in-the-wild study', 'browser extension', 'CSCW'.", "Searches recent proceedings (CSCW, UIST, CHI) for papers with methodologically similar evaluations.", "Generates a comparative summary of key study parameters (e.g., number of participants, study duration, metrics used) between the user's paper and established precedents.", "Provides pre-formatted citations that can be used in the rebuttal to defend the study's design, such as 'Our choice of metrics is consistent with prior in-the-wild research in this area [citation, citation].'"], "reasoning": "To defend the 'Fairness of the Evaluation,' the user will need to argue that their methods are sound. This tool provides the specific evidence and citations needed to benchmark their study against established community norms."}, {"name": "Narrative Impact Auditor", "functionalities": ["Scans the entire manuscript before a major change, such as 'remove the Linear Models'.", "Identifies all sentences, claims, and arguments that depend on the element being removed, going beyond simple keyword matching.", "Flags narrative inconsistencies, such as promising a three-model comparison in the introduction but only presenting two in the results section.", "Generates a 'Narrative To-Do List' of specific sentences and paragraphs that will require rewriting to maintain logical coherence after the revision."], "reasoning": "Removing the LM model has cascading effects on the paper's narrative. This tool helps the user proactively identify all the parts of their paper that need to be updated, preventing logical gaps and inconsistencies."}, {"name": "Public Deployment Evidence Scraper", "functionalities": ["Takes a URL to a public deployment (e.g., Chrome Web Store, project website).", "Automatically scrapes and extracts key evidence of success, such as the number of active users, average star rating, and representative positive user reviews.", "Summarizes this quantitative and qualitative data into concise bullet points or sentences formatted for inclusion in a rebuttal.", "Example output: 'To underscore its real-world value, Knoll has been successfully deployed and is currently used by over [Number] users, maintaining a [X]-star rating with reviews praising its ease of use.'"], "reasoning": "The user needs to highlight their 'successful public deployment and evaluation' as a key strength. This tool automates the gathering of concrete evidence to make this argument more quantitative and persuasive."}, {"name": "Contribution Type Identifier", "functionalities": ["Analyzes the abstract and reviewer comments to understand the paper's context.", "Draws on a knowledge base of HCI contribution frameworks (e.g., Wobbrock & Kientz's taxonomy of contribution types).", "Suggests the most appropriate contribution type for 'Knoll', such as framing it as an 'Empirical' contribution based on its in-the-wild study or an 'Artifact' contribution based on its plugable architecture.", "Provides templates for explicitly stating this contribution type in the rebuttal to address novelty concerns."], "reasoning": "The user is structuring arguments around 'Novelty of Interactions'. This tool helps them precisely define and articulate the *type* of novelty their work offers, using established academic frameworks to strengthen their claim."}], "7": [{"name": "Manuscript Coherence Validator", "functionalities": ["Scans the manuscript's narrative structure (Introduction, Methods, Results, Discussion) after a user specifies a major revision, such as 'remove Linear Models'.", "Identifies logical breaks in the argument, such as promising a three-model comparison in the introduction but only presenting two models in the results.", "Flags sentences in the discussion or conclusion that make claims based on the now-removed component (e.g., 'As the LM showed...').", "Generates a report of narrative inconsistencies that need to be addressed to maintain the paper's logical flow."], "reasoning": "This helps the user execute the required manuscript revision ('remove the LM') by ensuring the paper's core argument remains logically sound and coherent, which goes beyond simple reference checking."}, {"name": "Justification Scaffolder", "functionalities": ["User specifies a revision ('Removed LM') and the components that remain (e.g., models from Figures 2 & 3).", "Searches academic databases for papers that positively cite or use the remaining models in a similar research context.", "Extracts arguments from those papers that praise the strengths of the retained models.", "Generates several rebuttal phrasing options that justify the revision as a strategic choice to focus on more appropriate or robust methods, backed by the extracted evidence."], "reasoning": "This tool helps the user draft a stronger rebuttal by framing the required revision not as a correction, but as a strategic improvement supported by external, citable evidence from the research community."}, {"name": "Evaluation Strategy Mimic", "functionalities": ["User inputs the names of competing systems mentioned by reviewers, such as 'MCP' and 'RAG'.", "The tool automatically finds and fetches the original papers for these systems from academic databases.", "It specifically extracts and parses the 'Evaluation', 'User Study', or 'Experiment' sections of those papers.", "Presents a structured, side-by-side summary of the evaluation methodologies (metrics, participant counts, tasks, statistical tests) used for the competing systems."], "reasoning": "This tool directly helps the user address the 'Fairness of Evaluation' and 'Comparison to other Systems' critiques by providing a clear summary of how the gold-standard competitors were evaluated, arming the user with precedents to defend their own methodology."}, {"name": "Contribution Cost-Benefit Analyzer", "functionalities": ["Specifically targets critiques like 'Upfront Cost of Creating Modules'.", "User inputs the weakness noted by the reviewer (e.g., 'high setup cost').", "Scans CSCW/CHI/UIST proceedings for accepted papers with similar limitations (e.g., complex systems requiring significant authoring).", "Extracts the rhetorical strategies and specific phrasing those papers used to successfully frame the cost as a necessary trade-off for a significant benefit (e.g., expressiveness, flexibility)."], "reasoning": "This helps the user turn a potential rejection point ('upfront cost') into a defensible position by providing successful examples and rhetorical templates from previously published work at their target venue."}, {"name": "Results Impact Quantifier", "functionalities": ["Connects to the user's data analysis scripts (e.g., Python/R).", "Compares the statistical output from the analysis before and after a major change (e.g., removing the 'LM').", "Generates a 'delta report' that quantifies the impact of the change on key results, such as changes in coefficients, p-values, or effect sizes for the remaining models.", "Generates a summary sentence for the manuscript, such as 'After removing the LM, the effect size of our primary model increased by 0.12, strengthening our main finding.'"], "reasoning": "After the user removes the Linear Models, this tool helps them precisely understand and articulate the consequences of that revision, strengthening their results section and potentially uncovering positive outcomes to highlight."}, {"name": "Rebuttal-to-Code Linker", "functionalities": ["Allows a user to highlight a claim in the Google Doc rebuttal, such as 'We have removed the Linear Models from our analysis'.", "Creates a persistent link that can be anchored to specific lines of code in a local or remote repository (e.g., a specific commit hash in Git).", "Creates a verifiable, bi-directional audit trail between the high-level rebuttal promise and the low-level code that implements it.", "Generates a summary report showing which rebuttal promises have linked code changes and which do not."], "reasoning": "This tool provides a rigorous way to manage the 'remove the LM' task by directly connecting the promise made in the rebuttal to the actual code where the work was done, ensuring accountability and accuracy."}, {"name": "Interactive Figure Customizer", "functionalities": ["Ingests the data file used to generate Figures 2 and 3.", "Presents an interactive dashboard where data series (e.g., 'Linear Model', 'Model A', 'Model B') can be toggled on or off with checkboxes.", "The plot preview updates in real-time to reflect the selected data.", "Once finalized, the tool exports both the new figure as an image file (PNG/PDF) and the minimal code snippet required to generate that specific version."], "reasoning": "This tool accelerates the specific task of updating Figures 2 and 3 by replacing a slow code-edit-recompile loop with an immediate, visual interface, making it easier to produce the required revisions."}, {"name": "Reviewer Priority Matrix", "functionalities": ["Parses all comments from the review synthesis document.", "Automatically assesses each comment on two axes: 'Effort to Address' (e.g., 'low' for a typo, 'high' for removing a model) and 'Impact on Acceptance' (automatically weighting AC/meta-reviewer comments higher).", "Generates a visual 2x2 matrix that plots all reviewer points, helping the user see what is High-Impact/Low-Effort versus Low-Impact/High-Effort.", "Allows manual re-prioritization by dragging and dropping points within the matrix."], "reasoning": "This tool helps the user strategically plan their rebuttal and revision process by providing a clear, data-driven overview of where to focus their limited time and word count for maximum effect."}, {"name": "In-Context Competitor Assistant", "functionalities": ["Works as a sidebar within Google Docs.", "When the user types a competitor's acronym (e.g., 'RAG'), the tool automatically fetches the abstract and key claims from its canonical paper.", "The information is displayed directly in the sidebar, keeping the competitor's details visible while the user is writing their comparison.", "Allows the user to one-click copy a formatted citation for the competitor system."], "reasoning": "This tool improves the workflow for writing the 'Comparison to other Systems' section by eliminating the need to switch between windows, providing immediate, in-context information to draft a more accurate and detailed rebuttal."}, {"name": "Narrative Revision Mapper", "functionalities": ["User specifies a planned structural change, like 'remove Linear Models'.", "The tool creates a visual map of all claims in the paper that depend on the LM, including explicit mentions and implicit arguments in the discussion.", "It then generates a 'rewriting checklist' of specific paragraphs or sentences (e.g., 'Introduction, para 3', 'Discussion, para 1') that will need to be revised to maintain narrative integrity.", "As the user rewrites sections, they can check them off the list."], "reasoning": "This tool supports the complex revision task by transforming an abstract goal ('remove LM') into a concrete checklist of narrative edits, ensuring no part of the paper's story is accidentally broken."}], "8": [{"name": "Statistical Transformation Justifier", "functionalities": ["User specifies a variable ('OC') and a transformation ('log').", "Searches a corpus of CSCW/CHI/UIST papers for phrases justifying log transformations for similar data types (e.g., 'community size', 'user activity counts').", "Provides several template sentences for the manuscript's methods section, complete with relevant citations, to justify the transformation.", "Example output: 'To correct for the heavy-tailed distribution of community size, a common practice in computational social science [citation1, citation2], we applied a logarithmic transformation to the OC variable.'"], "reasoning": "This tool directly addresses the user's specific task of adding 'log(OC)' to their models by providing the academic precedent and ready-to-use text needed to justify this methodological choice in both the paper and the rebuttal."}, {"name": "Model-Coupled Figure Regenerator", "functionalities": ["Integrates with the user's plotting library (e.g., Matplotlib, ggplot2) by monitoring figure-generation scripts.", "Detects when a data series or model (e.g., 'LM') is commented out or removed from the script.", "Automatically regenerates the dependent figures (e.g., Figure 2, Figure 3) without the removed series.", "Intelligently adjusts plot aesthetics, such as legend placement and axis limits, to optimize the layout for the remaining data and avoid awkward empty space."], "reasoning": "This automates the tedious, multi-step process of updating figures after a model is removed, directly helping the user implement the 'remove LM but retain Figure 2 and Figure 3' task while ensuring the output is polished."}, {"name": "Narrative De-Tangler", "functionalities": ["After the user specifies a concept to remove (e.g., 'Linear Models'), this tool scans the manuscript's text.", "Uses semantic analysis to find not just keywords but also comparative statements (e.g., 'In contrast to the LM, our ZINB model...') and discussions of results related to the removed concept.", "Presents a queue of these 'tangled' sentences and paragraphs.", "Suggests rephrasing options that preserve the core argument about the remaining models while cleanly excising the removed one."], "reasoning": "Removing a model leaves narrative holes and inconsistencies in the Results and Discussion sections; this tool helps the user find and systematically fix all dependent text, ensuring the paper's argument remains coherent."}, {"name": "Revision Delta Reporter", "functionalities": ["Connects to the analysis script's version control (e.g., Git) or a local history.", "When the user finalizes a revision (e.g., removes LM, adds log transform), the tool runs the analysis with both the old and new code.", "Generates a 'delta report' summarizing how key statistical outputs (e.g., coefficients, p-values, AIC scores) have changed for the *remaining* models.", "Generates draft sentences for the results section, such as: 'After this revision, the ZINB model's AIC improved from X to Y, and the 'posts' coefficient increased by Z%.'"], "reasoning": "This tool answers the crucial question of how a revision impacted the rest of the results, providing the user with the precise quantitative data needed to accurately update the manuscript and understand the consequences of their changes."}, {"name": "Log Transformation Visualizer", "functionalities": ["User selects a variable from their dataset (e.g., 'OC').", "Generates a composite image displaying two plots side-by-side: a histogram of the raw data (showing its skew) and a histogram of the log-transformed data (showing its improved normality).", "Includes key statistics (e.g., skewness, Shapiro-Wilk test p-value) on both plots for comparison.", "Allows one-click export of the entire visual comparison, suitable for inclusion in a rebuttal appendix to transparently justify the transformation to reviewers."], "reasoning": "To justify the 'log(OC)' change, this tool creates a compelling visual argument that allows the user to 'show, not just tell' reviewers why the statistical transformation was necessary and appropriate, strengthening their rebuttal."}, {"name": "GDoc-to-Code Task Bridge", "functionalities": ["A plugin for a code editor (e.g., VS Code, PyCharm) that connects to the 'Memes CSCW review synthesis' Google Doc.", "Parses the document for checklist items or 'TODOs' that contain code-related terms (e.g., 'LM', 'log(OC)', 'ZINB').", "Creates an interactive task list directly within the IDE sidebar.", "When a user clicks a task like 'remove LM', it executes a project-wide search for that term and populates a list of all affected code files and lines."], "reasoning": "This tool reduces context switching by bringing the high-level revision plan from Google Docs directly into the low-level coding environment, ensuring the developer accurately implements the specific tasks required by the review synthesis."}, {"name": "Manuscript-Data Consistency Auditor", "functionalities": ["Scans the final compiled PDF of the paper and the data tables (e.g., CSV, JSON) generated by the final analysis script.", "Uses OCR to extract all numerical values from tables within the PDF.", "Compares these extracted numbers against the 'ground truth' values in the source data files.", "Flags any discrepancies, highlighting potential copy-paste errors or instances where an outdated table was inserted into the manuscript."], "reasoning": "Manually transcribing numbers from analysis outputs to manuscript tables is highly error-prone. This tool automates the final, critical proofreading step of verifying all reported data, ensuring the paper's results are perfectly consistent with the analysis."}, {"name": "Impact Statement Reframer", "functionalities": ["After the user confirms a major revision (e.g., 'LM removed'), the tool scans the abstract, introduction, and conclusion for high-level claims.", "It identifies statements that may now be invalid, such as claims about the number of models being compared.", "It prompts the user with the old claim and asks for confirmation, suggesting alternatives that reframe the contribution.", "Offers templates for changing a claim of 'breadth' (e.g., 'we compared three models') to one of 'depth' (e.g., 'we performed a focused, robust analysis of two state-of-the-art models')."], "reasoning": "Major revisions can invalidate the paper's core framing. This tool helps the user find and update their highest-level contribution claims, ensuring the paper's introduction and conclusion accurately reflect the revised content."}, {"name": "Methodology Precedent Finder", "functionalities": ["User inputs their methodology keywords ('ZINB model', 'in-the-wild study', 'community size').", "Searches recent CSCW, CHI, and UIST proceedings for accepted papers that used similar methods.", "Extracts and summarizes how those papers justified their choices, handled common data issues (like skew), and positioned their work.", "Provides a list of relevant citations and phrasing examples that can be used to bolster the rebuttal and methods section."], "reasoning": "This tool helps the user defend their methodological choices (like using ZINB models and log transformations) by grounding them in the accepted practices of their specific research community, saving significant literature review time."}, {"name": "Doomed Reference Linter", "functionalities": ["Performs a static analysis of the LaTeX source code before compilation.", "Identifies `\\label` commands that are inside code blocks that are currently commented out (e.g., `\\begin{comment} ... \\label{fig:old_lm} ... \\end{comment}`).", "It then finds all `\\ref` commands in the manuscript that point to these 'doomed' labels.", "Generates a clear report of these future broken references, allowing the user to fix them before they appear as '???' in the compiled PDF."], "reasoning": "When commenting out large sections or figures during revision, it's easy to forget to remove references to them. This tool proactively finds these future errors, preventing broken cross-references and improving the final document's professionalism."}]}