{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0135f19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import textwrap\n",
    "\n",
    "import asyncio\n",
    "from prompts.hypothesis_generation import HYPOTHESIS_GENERATION_PROMPT, HYPOTHESIS_EVALUATION_PROMPT, HYPOTHESIS_RANK_PROMPT\n",
    "from response_formats import HypothesisResponse, HypothesisEvalResponse, HypothesisRankResponse\n",
    "from utils import call_gpt\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb31d91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AsyncOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82e6b5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fidx = \"40\"\n",
    "data = json.load(open(f'infact_dataset/results/llm_pipeline_alt/{fidx}_o4-mini_20251009.json'))\n",
    "all_observations = [f\"ID {k} | {v['description']}\" for k, v in data.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a056b837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Observation: Michelle’s workflow embodies a continuous, tightly coupled loop between software development, quantitative experimentation, and qualitative analysis, where insights from each domain immediately drive changes in the others.\\nEvidence: [\\'She runs best-of-N experiments in Jupyter and modular_pipeline.py, then pivots to editing Svelte components and survey content in VS Code and Obsidian (IDs 2, 127), and simultaneously refines interview summaries and usability feedback in Google Docs (IDs 225, 249, 274).\\', \\'Michelle simultaneously edits Svelte front-end components (ObservationSelector.svelte), tunes Python pipelines in Jupyter (modular_pipeline.py), and revises interview notes in Google Docs (‘Eval hub’), suggesting she leverages live user feedback to directly shape both experiment design and UI/backend code.\\', \"In every timestep (IDs 225, 274, 397) she simultaneously edits \\'Eval hub\\' interview bullets in Google Docs while debugging Python/Svelte code and running Jupyter experiments, directly translating participant feedback into code and experiment adjustments.\"]']\n"
     ]
    }
   ],
   "source": [
    "options = []\n",
    "for k, v in data.items():\n",
    "    if 'interesting' in v and v['interesting'] == 1 and v['confidence'] > 5:\n",
    "        options.append(v)\n",
    "observations = []\n",
    "raw_obs = []\n",
    "tasks = []\n",
    "for o in options:\n",
    "    raw_obs.append(o)\n",
    "    item = f\"Observation: {o['description']}\\nEvidence: {o['evidence']}\"\n",
    "    observations.append(item)\n",
    "    tasks.append(call_gpt(client=client, prompt=HYPOTHESIS_GENERATION_PROMPT.format(observations=item, limit=5), \\\n",
    "        model=\"gpt-5\", resp_format=HypothesisResponse))\n",
    "print(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3d69dc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This behavior—pushing sample sizes/parallelism for better best-of-N and then throttling due to 429s—is common and expected when working with API rate limits. It doesn’t uniquely reveal something about Michelle beyond standard performance tuning trade-offs, so it’s not particularly surprising or user-specific.\n",
      "This describes a common developer workflow: keeping front-end and server running while focusing work on backend/model code. It doesn’t reveal a distinctive or unexpected personal pattern beyond typical role-based behavior, and could be reasonably guessed without observing this specific user.\n",
      "Collapsing verbose logs and displaying only key columns are common notebook hygiene practices to manage clutter and focus on results. The behavior is expected for many users running experiments and doesn’t reveal a unique or surprising personal strategy beyond standard workflow optimization. The evidence doesn’t strongly support the more specific claim of using clear/collapse as stage markers, making the insight not uniquely about the user.\n",
      "This describes common best practices (timestamped filenames, participant-scoped paths, provenance/auditability comments) that many data scientists use. It doesn’t reveal a unique or surprising trait about Michelle beyond standard reproducibility habits, so it’s not particularly interesting.\n",
      "This describes a common, expected pain point in data/ML workflows—manual parameter propagation between notebooks and configs leading to brittle sync and errors. While the evidence is concrete (TODOs, search-based edits, a missing parameter TypeError), the conclusion isn’t unique or surprising about Michelle specifically. Many practitioners using Pydantic/config classes and notebooks experience the same friction, so this could be guessed without observing this particular user and doesn’t reveal a distinctive trait or unexpected behavior.\n",
      "While accurate, the behaviors described (retry logic, async concurrency, batch-size tuning after parse or rate-limit errors) are standard, widely adopted practices for LLM/API experimentation. They don’t uniquely reveal something about Michelle beyond being a competent practitioner, and could be reasonably guessed without observing her specifically. Thus, it’s not particularly surprising or unique to the user.\n",
      "It reveals a distinctive, user-specific working style: Michelle repeatedly and simultaneously integrates qualitative feedback into quantitative experiments and live code/UI changes within the same sessions. This tight, real-time coupling across qual, quant, and development is not a generic assumption and is evidenced by concurrent edits across Jupyter, Svelte, and interview notes, making it a non-obvious insight about how she uniquely works.\n",
      "While well-evidenced, the behavior (split-screening transcripts with notes, pausing to copy quotes, memoing and coding inline) is standard for qualitative analysis and could be reasonably predicted for anyone reviewing transcripts. It doesn’t reveal a unique, surprising trait about Michelle beyond being a diligent qualitative researcher, so it’s not particularly interesting.\n",
      "This behavior—using hover tooltips/IntelliSense, split panes for side-by-side comparisons, search and symbol outline, and a conda environment—is standard practice for many developers working in complex Python codebases. The insight reads as a generic description of common IDE-driven workflows rather than a unique or surprising pattern specific to Michelle. It could be reasonably guessed without observing her directly.\n",
      "This behavior—running experiments with varying parameters, inserting print statements, and inspecting code to verify automated outputs—is a common, expected debugging and validation workflow among developers and researchers. It does not reveal a uniquely personal or surprising trait about Michelle beyond standard best practices.\n",
      "This insight restates a common, expected preference: users value AI outputs that are expert-informed, context-specific, and voice-aligned over generic responses. While it references Michelle’s process (expert entities, pattern selection), the conclusion is broadly applicable and not uniquely revealing about Michelle’s personal needs or idiosyncrasies. It could be guessed without observing her specifically, so it’s not interesting under the given criteria.\n",
      "This is a generic, well-known UX principle (users trade initial friction for better outcomes) and not unique to the specific user. It doesn't reveal a distinctive trait about Michelle beyond common behavior, and could have been predicted without observing her.\n",
      "This synthesis is plausible and evidence-backed but not surprising or unique. Many experienced ChatGPT users anchor expectations to it, value high-quality structured outputs, struggle with unfamiliar UIs, and ask for visual exploration and explicit sourcing. The insight generalizes common patterns rather than revealing something distinctive or unexpected about Michelle specifically.\n",
      "This describes fairly standard research practice (capturing verbatim quotes, adding bracketed context, maintaining traceability). While the autoscroll pausing is a specific behavior, the overall insight—that she builds an audit trail and emphasizes evidentiary rigor—could be reasonably inferred about many conscientious researchers and isn’t uniquely revealing or surprising about this user.\n"
     ]
    }
   ],
   "source": [
    "for k, v in data.items():\n",
    "    if 'interesting' in v:\n",
    "        print(v['reasoning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8fb3dd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypotheses=[Hypothesis(text='Shortening the Learning Loop', description='She prioritizes minimizing the time from user signal to product change to accelerate discovery and reduce rework, believing speed of iteration is the main competitive advantage.'), Hypothesis(text='Guarding Against Silo Drift', description='She distrusts handoffs and wants to preserve the nuance of user feedback, so she keeps research, experimentation, and coding tightly integrated to ensure fidelity to user needs.'), Hypothesis(text='Parallel Work as Focus Regulation', description='Her cognitive style benefits from high stimulation and continuous context linking; bouncing among code, experiments, and notes helps maintain flow and prevents loss of tacit insights.'), Hypothesis(text='Building Defensible Evidence', description='She anticipates stakeholder scrutiny and uses a mixed-methods trail—qual quotes, quant results, and immediate code changes—to justify decisions and secure buy-in.'), Hypothesis(text='Scarcity-Driven Full-Stacking', description='Operating under startup-like constraints or looming deadlines, she collapses roles so every research insight immediately ships to product, trading depth in one area for overall velocity.')]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "resp = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "for r in resp:\n",
    "    print(r)\n",
    "    print('-'*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9446c414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michelle’s workflow embodies a continuous, tightly coupled loop between software\n",
      "development, quantitative experimentation, and qualitative analysis, where\n",
      "insights from each domain immediately drive changes in the others.\n",
      "\n",
      "\n",
      "Shortening the Learning Loop\n",
      "She prioritizes minimizing the time from user signal to product change to\n",
      "accelerate discovery and reduce rework, believing speed of iteration is the main\n",
      "competitive advantage.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Guarding Against Silo Drift\n",
      "She distrusts handoffs and wants to preserve the nuance of user feedback, so she\n",
      "keeps research, experimentation, and coding tightly integrated to ensure\n",
      "fidelity to user needs.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Parallel Work as Focus Regulation\n",
      "Her cognitive style benefits from high stimulation and continuous context\n",
      "linking; bouncing among code, experiments, and notes helps maintain flow and\n",
      "prevents loss of tacit insights.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Building Defensible Evidence\n",
      "She anticipates stakeholder scrutiny and uses a mixed-methods trail—qual quotes,\n",
      "quant results, and immediate code changes—to justify decisions and secure buy-\n",
      "in.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Scarcity-Driven Full-Stacking\n",
      "Operating under startup-like constraints or looming deadlines, she collapses\n",
      "roles so every research insight immediately ships to product, trading depth in\n",
      "one area for overall velocity.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "print(textwrap.fill(options[idx]['description'], width=80))\n",
    "print('\\n')\n",
    "for i in resp[idx].hypotheses:\n",
    "    print(textwrap.fill(i.text, width=80))\n",
    "    print(textwrap.fill(i.description, width=80))\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "15ec1eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for i, r in enumerate(resp):\n",
    "    observation = raw_obs[i]\n",
    "    output.append({\n",
    "        'observation': observation['description'],\n",
    "        'evidence': observation['evidence'],\n",
    "        'hypotheses': [h.model_dump() for h in r.hypotheses]\n",
    "    })\n",
    "json.dump(output, open(f'infact_dataset/results/llm_pipeline_alt/{fidx}_o4-mini_20251009_hypotheses.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f51970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hypotheses = json.load(open(f'infact_dataset/results/llm_pipeline_alt/{fidx}_o4-mini_20251009_hypotheses.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df01826f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = []\n",
    "\n",
    "for item in all_hypotheses[:]:\n",
    "    hypotheses = item['hypotheses']\n",
    "    behavior = item['observation']\n",
    "    options = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
    "    fmt_hypotheses = []\n",
    "    for i, h in enumerate(hypotheses):\n",
    "        string_fmt = f\"{options[i]}. {h['text']}: {h['description']}\"\n",
    "        fmt_hypotheses.append(string_fmt)\n",
    "    fmt_obs = \"\\n\".join([f\"ID {k} | {v['description']}\" for k, v in data.items() if v['description'] != behavior])\n",
    "    # fmt_hypotheses = \"\\n\".join(fmt_hypotheses)\n",
    "    prompt = HYPOTHESIS_RANK_PROMPT.format(hypotheses=fmt_hypotheses, observations=fmt_obs, behavior=behavior)\n",
    "    tasks.append(call_gpt(client=client, prompt=prompt, model=\"gpt-5\", resp_format=HypothesisRankResponse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c2e8501",
   "metadata": {},
   "outputs": [],
   "source": [
    "resps = await asyncio.gather(*tasks, return_exceptions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d21debcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dora’s proposal exhibits a lopsided focus on large-scale data sourcing while leaving the core model training strategy underdefined and repeatedly deferred to collaborators, creating a planning imbalance that threatens to bottleneck project execution.\n",
      "A. Leaning Into Strengths, Avoiding Weaknesses: Dora is confident in data sourcing but lacks expertise in model training, so she over-specifies collection and defers modeling to reduce personal risk and anxiety. She prioritizes delivering where she feels competent and expects collaborators to cover the training gap.\n",
      "B. Critical-Path Optimization: She believes data acquisition is the true schedule bottleneck and thus front-loads detailed plans there while leaving training flexible until data characteristics are known. This reflects pragmatic sequencing, even if it creates a short-term planning imbalance.\n",
      "*C. Role Deference and Boundary Management: Team norms or prior ownership may assign training to Omar, prompting Dora to leave placeholders to avoid overstepping. She values social harmony and clear responsibilities more than drafting a fully cross-functional plan.\n",
      "D. Signaling Scale to Secure Buy-in: The emphasis on massive datasets is a persuasion tactic to impress stakeholders and justify resources, assuming training recipes are relatively standard. She aims to win approval first and fill in training specifics later.\n",
      "E. Building a Data Asset as the True Goal: Dora may view the dataset as the enduring asset for the organization or her portfolio, treating model training as interchangeable. She prioritizes creating a unique, reusable data resource over committing to a specific training strategy now.\n",
      "\n",
      "\n",
      "Dora’s obsessive iterative formatting behaviors—constant recompilation, global find-and-replace, and fine-tuned LaTeX tweaks—function less as efficiency optimizations and more as an emotional regulation strategy to manage the uncertainty of high-stakes grant writing.\n",
      "*A. Control-Seeking to Soothe Uncertainty: She uses rapid compile-feedback loops to create a sense of control over an inherently uncertain, high-stakes task. Instant visual confirmation stabilizes her emotions so she can keep working.\n",
      "B. Impression Management for Reviewer Scrutiny: She believes reviewers equate visual polish with rigor, so she over-optimizes formatting to safeguard credibility. The tweaks are a preemptive defense against perceived nitpicking and reputational risk.\n",
      "C. Productive Procrastination from Content Decisions: Micro-optimizations provide a safe, ‘busy’ refuge from thorny conceptual or narrative choices. She substitutes low-risk tweaks for high-ambiguity thinking to reduce discomfort while still feeling productive.\n",
      "D. Attention and Motivation Regulation via Micro-Rewards: Each successful tweak yields a small dopamine hit and a cognitive reset, helping her pace long writing sessions. The compile button acts as a self-administered rhythm to manage focus and fatigue.\n",
      "E. Future-Proofing and Maintainability Mindset: Her enumitem-versus-core debates reflect a desire for portability and robustness across venues and collaborators. She invests in durable LaTeX patterns now to avoid downstream friction and rework.\n",
      "\n",
      "\n",
      "Dora’s strategy professionalizes academic ML research by applying product-style development practices—precise cloud budgeting, modular LLM agent design, and privacy engineering—to transform scholarly workflows into production-like pipelines, a shift that may boost reproducibility while increasing vendor lock-in and emphasis on measurable deliverables.\n",
      "A. Reproducibility-Driven Engineering: She prioritizes making ML research repeatable and auditable, using production-style pipelines to reduce variance and enable large-scale verification of results.\n",
      "*B. Funding Signal and Accountability: Precise budgets and measurable milestones are deliberate signals to funders and administrators that the work is low-risk, manageable, and worth sustained investment.\n",
      "C. Industry-Inflected Identity and Career Positioning: She identifies with product management practices and is crafting a differentiated academic profile that can translate into platform leadership or a future spinout.\n",
      "D. Compliance and Reputation Risk Management: Embedding privacy guarantees and strict platform choices anticipates IRB and regulatory scrutiny, aiming to avoid ethical failures and protect the lab’s reputation.\n",
      "E. Strategic Standard-Setting via Platform Lock-In: By scaling on specific clouds and repositories, she seeks to establish de facto standards others must follow, creating network effects, influence, and bargaining power despite increased vendor dependence.\n",
      "\n",
      "\n",
      "Dora’s repeated use of ‘gum’ to generate and score propositions transforms her workflow refinement into a formal hypothesis-testing cycle, externalizing problem identification and solution iteration for budgeting, collaboration, and citation management.\n",
      "*A. Reducing Cognitive Load with Structured Experiments: She uses gum’s scored propositions to externalize options and tame complexity across budgeting, collaboration, and citations. The hypothesis-testing cycle turns fragmented feedback into comparable, bite-sized decisions.\n",
      "B. Building Traceable Justifications for Stakeholders: By scoring and queuing propositions, she creates an auditable rationale for budget and organization choices. The formal framing helps secure alignment and defend priorities to collaborators or leadership.\n",
      "C. Combating Imposter Syndrome via Quantified Decisions: She may distrust purely intuitive choices, so she leans on score-driven iterations to feel confident. Objective-seeming evidence reduces anxiety about being second-guessed.\n",
      "D. Bootstrapping a Personal Decision Engine: She could be prototyping a meta-workflow where gum coordinates planning and knowledge management across fragmented tools. Repeated runs and queue checks calibrate a semi-autonomous system to guide future decisions.\n",
      "E. Gamifying Progress to Sustain Motivation: Frequent scored runs provide quick feedback and small wins, turning ambiguous work into measurable iterations. This gamified loop helps her maintain momentum despite scattered tool signals.\n",
      "\n",
      "\n",
      "Dora treats Overleaf primarily as a private drafting tool rather than a real-time collaboration platform, deferring actual peer review and feedback integration until a later stage.\n",
      "*A. Protecting Draft Quality and Self-Presentation: She may be a perfectionist who wants others to see only polished work, delaying external feedback to protect her credibility and avoid premature judgment.\n",
      "B. Preserving Focus by Batching Feedback: Real-time comments can fracture attention, so she uses Slack placeholders to stay in flow and later incorporate feedback in a controlled, batched pass for efficiency.\n",
      "C. Adhering to Team Norms and Tool Constraints: Her collaborators might be uncomfortable with or lack access to Overleaf’s review features, making Slack the de facto feedback channel and reducing coordination friction.\n",
      "D. Controlling the Narrative and Power Dynamics: By keeping feedback off the live document, she can curate which suggestions make it in and maintain a coherent authorial voice, minimizing visible dissent or dilution of ownership.\n",
      "E. Avoiding Permanent Paper Trails: She may worry about persistent comment histories, auditability, or IP exposure on Overleaf, preferring Slack’s more ephemeral or contained record for sensitive feedback.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item, resp in zip(all_hypotheses, resps):\n",
    "    selection = resp.selection\n",
    "    hypotheses = item['hypotheses']\n",
    "    print((item['observation']))\n",
    "    fmt_hypotheses = []\n",
    "    for i, h in enumerate(hypotheses):\n",
    "        if options[i] == selection:\n",
    "            string_fmt = f\"*{options[i]}. {h['text']}: {h['description']}\"\n",
    "        else:\n",
    "            string_fmt = f\"{options[i]}. {h['text']}: {h['description']}\"\n",
    "        fmt_hypotheses.append(string_fmt)\n",
    "    print(\"\\n\".join(fmt_hypotheses))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9875f91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HypothesisRankResponse(selection='C', reasoning='Repeated, explicit deferral of the Training section to Omar (IDs 15, 23, 289) alongside direct edit requests to “DORA/OMAR” (ID 63) and evidence of shared ownership norms (IDs 223, 227) point to role boundaries more than lack of capability. Dora demonstrates broad ML fluency (IDs 24, 285) and sophisticated planning, suggesting she’s not fundamentally unable but is respecting team division of labor. The strong, detailed emphasis on data sourcing (IDs 14, 260) creates the planning imbalance, but the decisive factor is deference to the teammate responsible for training rather than a purely strategic bottleneck focus (B) or signaling (D) or a belief that training is interchangeable (E). This pattern best fits Role Deference and Boundary Management.'),\n",
       " HypothesisRankResponse(selection='A', reasoning='Multiple observations show high uncertainty and pressure (IDs 15, 23, 61, 105, 149, 158, 165, 289, 291) alongside hyper-vigilant monitoring and tool friction (IDs 30, 125, 148, 245, 249, 254, 286, 301). Her repeated recompiles, global find/replace, and fine-grained LaTeX tweaks provide immediate, controllable feedback during a high-stakes, ambiguous task, fitting emotional regulation via control-seeking. She continues substantive drafting in parallel (IDs 285, 299, 302), which argues against pure procrastination (C) or primarily impression management (B). Micro-reward pacing (D) and maintainability (E) appear secondary (e.g., enumitem debate in 254), but the dominant pattern is using compile-feedback loops to stabilize emotions and regain control under uncertainty—consistent with A.'),\n",
       " HypothesisRankResponse(selection='B', reasoning='Multiple observations point to budgeting precision and milestone-driven framing as signals to funders: benchmarking against another team to look ‘serious’ (48), tension over GCP credits (46), fixed timelines and concrete deliverables (69, 112), explicit alignment with grant requirements (143), presentation polish aimed at review committees (255), and Dora’s role as budget authority/interface to funders with upward pressure on numbers (12, 290). While engineering rigor/logging (191, 286) and privacy concern (110) exist, they appear in service of accountability and fundability rather than as primary goals. Thus, funding signal and accountability best explain the professionalized, production-style approach and emphasis on measurable deliverables.'),\n",
       " HypothesisRankResponse(selection='A', reasoning='Her gum usage explicitly externalizes and scores propositions to structure messy decisions across budgeting, collaboration, and citations (IDs 84, 88, 287). The pattern—trial-and-error runs, queue checks, and improved logging/env handling (IDs 286, 191, 188)—shows a hypothesis-testing loop to tame fragmented feedback and complexity (ID 301). While B and D are plausible, there’s no clear evidence she’s packaging outputs as stakeholder-facing audit trails (B) or achieving semi-autonomous orchestration (D). E and C lack direct support. Therefore A best fits the observed behavior.'),\n",
       " HypothesisRankResponse(selection='A', reasoning='Multiple observations indicate a perfectionist, polish-first workflow: she avoids Overleaf’s collaborative features (IDs 106, 109), leaves placeholders for later (IDs 21, 161, 227) while privately iterating, and shows meticulous attention to formatting and presentation to impress reviewers (IDs 245–255, 292, 299). She repeatedly recompiles and fine-tunes text and citations (IDs 125, 148, 167, 170, 285, 302), consistent with wanting others to see only a refined draft. There’s no strong evidence that tool access norms (C), power-play curation (D), or IP/paper-trail concerns (E) drive this choice, and while batching feedback (B) may be a side benefit, the dominant signal is protecting draft quality and self-presentation.')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14510d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "community_lm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
